# ğŸ§  The Perceptron

The perceptron is one of the earliest and most fundamental building blocks of modern machine learning algorithms. It was introduced in 1958 by Frank Rosenblatt and was inspired by how neurons fire in the brain. It was applied by Rosenblatt in a visual pattern recognition task where it learned to recognize simple black and white shapes (e.g. squares or triangles) within a 20x20 grid of light-sensitive cells (400 pixesl). 

---

## ğŸ§® How the Perceptron Works

The Perceptron is a simple learning algorithm used for binary classification tasks. It attempts to find a linear decision boundary that separates the two classes by learning an n+1-dimensional set of weights. Each weight is connected to an input feauture, which is also n-dimensional. The input features are denoted by:

x = [xâ‚, xâ‚‚, ..., xâ‚™]



---

## ğŸš€ What is a Perceptron?

A *perceptron* is one of the simplest types of artificial neural networks, used for binary classification tasks. It learns a linear decision boundary between two classes by adjusting weights based on classification errors.

---



## ğŸ“š References

Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. *Psychological Review, 65*(6), 386â€“408. https://doi.org/10.1037/h0042519

